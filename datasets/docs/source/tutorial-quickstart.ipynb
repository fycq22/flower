{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "79c178bc47ac1b2f",
      "metadata": {
        "id": "79c178bc47ac1b2f"
      },
      "source": [
        "# Quickstart\n",
        "\n",
        "Start with `Flower Datasets` as fast as possible by learning the essentials."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "lPy04VYA87q4",
        "outputId": "96cb2aca-d272-4f55-d122-ee4b85bb0a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lPy04VYA87q4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "每次启动都要重新运行安装各种包，下面这行运行两遍才能成功"
      ],
      "metadata": {
        "id": "ItT6ZQ2Oi7w4"
      },
      "id": "ItT6ZQ2Oi7w4"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "MAmQBDjki2sy"
      },
      "id": "MAmQBDjki2sy",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "CdcxABVi9Wwb",
        "outputId": "385bdc8c-d3b5-4ad0-a751-90ba0d24610e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CdcxABVi9Wwb",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.20.0 / PyTorch 2.8.0+cu126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f34a29f74b13cb",
      "metadata": {
        "id": "e0f34a29f74b13cb"
      },
      "source": [
        "## Install Flower Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "initial_id",
      "metadata": {
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "! pip install -q \"flwr-datasets[vision]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f19a191a",
      "metadata": {
        "id": "f19a191a"
      },
      "source": [
        "If you want to use audio datasets install:\n",
        "\n",
        "```bash\n",
        "! pip install -q \"flwr-datasets[audio]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "flag1-25-9-4"
      ],
      "metadata": {
        "id": "SRzUnx5QhdVE"
      },
      "id": "SRzUnx5QhdVE"
    },
    {
      "cell_type": "markdown",
      "id": "499dd2f0d23d871e",
      "metadata": {
        "id": "499dd2f0d23d871e"
      },
      "source": [
        "## Choose the dataset\n",
        "\n",
        "To choose the dataset, go to Hugging Face [Datasets Hub](https://huggingface.co/datasets) and search for your dataset by name. You will pass that names to the `dataset` parameter of `FederatedDataset`. Note that the name is case-sensitive.\n",
        "\n",
        "<div style=\"max-width:80%; margin-left: auto; margin-right: auto;\">\n",
        "  <img src=\"https://github.com/fycq22/flower/blob/main/datasets/docs/source/_static/tutorial-quickstart/choose-hf-dataset.png?raw=1\" alt=\"Choose HF dataset.\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d449e6",
      "metadata": {
        "id": "a9d449e6"
      },
      "source": [
        "Note that once the dataset is available on HuggingFace Hub it can be immediately used in `Flower Datasets` (no approval from Flower team is needed, no custom code needed).\n",
        "\n",
        "Here is how it looks for `CIFAR10` dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d66b23efb1a289",
      "metadata": {
        "id": "b7d66b23efb1a289"
      },
      "source": [
        "<div style=\"max-width:80%; margin-left: auto; margin-right: auto;\">\n",
        "  <img src=\"https://github.com/fycq22/flower/blob/main/datasets/docs/source/_static/tutorial-quickstart/copy-dataset-name.png?raw=1\" alt=\"Choose HF dataset.\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c146753048fb2a",
      "metadata": {
        "id": "e0c146753048fb2a"
      },
      "source": [
        "## Partition the dataset\n",
        "\n",
        "To partition a dataset (in a basic scenario), you need to choose two things:\n",
        "1) A dataset (identified by a name),\n",
        "2) A partitioning scheme (by selecting one of the supported partitioning schemes, [see all of them here](https://flower.ai/docs/datasets/ref-api/flwr_datasets.partitioner.html), or creating a custom partitioning scheme).\n",
        "\n",
        "\n",
        "\n",
        "**1) Dataset choice**\n",
        "\n",
        "We will pass the name of the dataset to `FederatedDataset(dataset=\"some-name\", other-parameters)`. In this example it will be: `FederatedDataset(dataset=\"uoft-cs/cifar10\", other-parameters)`\n",
        "\n",
        "**2) Partitioner choice**\n",
        "\n",
        "We will partition the dataset in an IID manner using `IidPartitioner` ([link to the docs](https://flower.ai/docs/datasets/ref-api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner)).\n",
        "Only the train split of the dataset will be processed. In general, we do `FederatedDataset(dataset=\"some-name\", partitioners={\"split-name\": partitioning_scheme})`, which for this example looks like:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "由于我们只有一个csv文件，因此需要自己划分测试集和训练集。此外我们还需要把Label从value修改为Classlabel。"
      ],
      "metadata": {
        "id": "rqxb3ZOdkhyB"
      },
      "id": "rqxb3ZOdkhyB"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a759c5b6f25c9dd4",
      "metadata": {
        "id": "a759c5b6f25c9dd4",
        "outputId": "fdf8d534-7cdf-4f86-90f2-0fe2c2f23bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/flwr_datasets/utils.py:109: UserWarning: The currently tested dataset are ['mnist', 'ylecun/mnist', 'cifar10', 'uoft-cs/cifar10', 'fashion_mnist', 'zalando-datasets/fashion_mnist', 'sasha/dog-food', 'zh-plus/tiny-imagenet', 'scikit-learn/adult-census-income', 'cifar100', 'uoft-cs/cifar100', 'svhn', 'ufldl-stanford/svhn', 'sentiment140', 'stanfordnlp/sentiment140', 'speech_commands', 'LIUM/tedlium', 'flwrlabs/femnist', 'flwrlabs/ucf101', 'flwrlabs/ambient-acoustic-context', 'jlh/uci-mushrooms', 'Mike0307/MNIST-M', 'flwrlabs/usps', 'scikit-learn/iris', 'flwrlabs/pacs', 'flwrlabs/cinic10', 'flwrlabs/caltech101', 'flwrlabs/office-home', 'flwrlabs/fed-isic2019']. Given: fycq22/CICIDS-171819.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Stratifying by column is only supported for ClassLabel column, and column Label is Value.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2317608664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 从 train split 中划分出唯一的 centralized test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify_by_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mcentralized_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         }\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(self, test_size, train_size, shuffle, stratify_by_column, seed, generator, keep_in_memory, load_from_cache_file, train_indices_cache_file_name, test_indices_cache_file_name, writer_batch_size, train_new_fingerprint, test_new_fingerprint)\u001b[0m\n\u001b[1;32m   4843\u001b[0m                 \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mChanged\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4845\u001b[0;31m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4846\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mint\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcharacters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0mwritten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Stratifying by column is only supported for ClassLabel column, and column Label is Value."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import IidPartitioner\n",
        "\n",
        "# 创建 FederatedDataset，只对 train 做分区\n",
        "fds = FederatedDataset(\n",
        "    dataset=\"fycq22/CICIDS-171819\",\n",
        "    partitioners={\"train\": IidPartitioner(num_partitions=10)},\n",
        ")\n",
        "\n",
        "# 加载第一个 partition (client 0 的训练集)\n",
        "partition = fds.load_partition(0, \"train\")\n",
        "\n",
        "# 加载完整的 train split（未分区）\n",
        "full_train = fds.load_split(\"train\")\n",
        "\n",
        "# 从 train split 中划分出唯一的 centralized test\n",
        "dataset = full_train.train_test_split(test_size=0.2, seed=42, stratify_by_column=\"Label\")\n",
        "centralized_test = dataset[\"test\"]\n",
        "\n",
        "print(f\"Partition size (client 0 train): {len(partition)}\")\n",
        "print(f\"Centralized test size: {len(centralized_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de75d15c3f5b2383",
      "metadata": {
        "id": "de75d15c3f5b2383"
      },
      "source": [
        "Now we have 10 partitions created from the train split of the CIFAR10 dataset and the test split\n",
        "for the centralized evaluation. Later we will convert the type of the dataset from Hugging Face's `Dataset` type to the format required by PyTorch/TensorFlow frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa7dbb120505f1f",
      "metadata": {
        "id": "efa7dbb120505f1f"
      },
      "source": [
        "## Investigate the partition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf986a1a9f0284cd",
      "metadata": {
        "id": "bf986a1a9f0284cd"
      },
      "source": [
        "### Features\n",
        "\n",
        "Now we will determine the names of the features of your dataset (you can alternatively do that directly on the Hugging Face\n",
        "website). The names can vary along different datasets e.g. \"img\" or \"image\", \"label\" or \"labels\". Additionally, if the label column is of [ClassLabel](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.ClassLabel) type, we will also see the names of labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ff7cecdda8a931",
      "metadata": {
        "id": "f7ff7cecdda8a931",
        "outputId": "3a84bf7b-3a1f-44a5-950b-5440a8a25aab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'img': Image(mode=None, decode=True, id=None),\n",
              " 'label': ClassLabel(names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], id=None)}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note this dataset has\n",
        "partition.features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e69ed05193a098a",
      "metadata": {
        "id": "2e69ed05193a098a"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "To see the first sample of the partition, we can index it like a Python list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2097d4c5121a1b",
      "metadata": {
        "id": "2f2097d4c5121a1b",
        "outputId": "8efe96b0-ac7d-412e-912b-07b4698248c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'img': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              " 'label': 1}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10ad2b97c4dd92a",
      "metadata": {
        "id": "a10ad2b97c4dd92a"
      },
      "source": [
        "Then we can additionally choose the specific column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7f0e2e29841f54",
      "metadata": {
        "id": "aa7f0e2e29841f54",
        "outputId": "77f848f0-bb56-4e68-e2b4-71512ce56d8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition[0][\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe1cef9a121dbc5",
      "metadata": {
        "id": "3fe1cef9a121dbc5"
      },
      "source": [
        "We can also use slicing (take a few samples). Let's take the first 3 samples of the first partition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779818b365682c60",
      "metadata": {
        "id": "779818b365682c60",
        "outputId": "07d4d719-7c07-4475-d148-3b4bae0121d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'img': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>],\n",
              " 'label': [1, 2, 6]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a354aa36fc586438",
      "metadata": {
        "id": "a354aa36fc586438"
      },
      "source": [
        "We get a dictionary where the keys are the names of the columns and the values are list of the corresponding values of each row of the dataset. So to take the first 3 labels we can do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fca62a8f2fbe51",
      "metadata": {
        "id": "25fca62a8f2fbe51",
        "outputId": "342b0ab8-581a-4af6-ee49-fba6df23c783"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 6]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition[:3][\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4790671ffe2142",
      "metadata": {
        "id": "4e4790671ffe2142"
      },
      "source": [
        "Note that the indexing by column first is also possible but discouraged because the whole column will be loaded into the memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7836fe6d65c673b2",
      "metadata": {
        "id": "7836fe6d65c673b2",
        "outputId": "e0a1e4e1-10cb-47e7-c117-8cf7b8ada8cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 6]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition[\"label\"][:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c46099625437fc",
      "metadata": {
        "id": "c3c46099625437fc"
      },
      "source": [
        "You can also select a subset of the dataset and keep the same type (dataset.Dataset) instead of receiving a dictionary of values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708abab74de3d5a1",
      "metadata": {
        "id": "708abab74de3d5a1",
        "outputId": "c68f21c9-777c-4b23-e0d7-ca9c92b47237"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['img', 'label'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition.select([0, 1, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462f707b4f078a8d",
      "metadata": {
        "id": "462f707b4f078a8d"
      },
      "source": [
        "And this dataset contains the same samples as we saw before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d2e3cc74d93c4d",
      "metadata": {
        "id": "19d2e3cc74d93c4d",
        "outputId": "c0118b2a-4aaf-4009-f78d-7768f81b0669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'img': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>],\n",
              " 'label': [1, 2, 6]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition.select([0, 1, 2])[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5e683cfaddf92f",
      "metadata": {
        "id": "b5e683cfaddf92f"
      },
      "source": [
        "## Use with PyTorch/NumPy/TensorFlow\n",
        "\n",
        "For more detailed instructions, go to:\n",
        "\n",
        "* [how-to-use-with-pytorch](https://flower.ai/docs/datasets/how-to-use-with-pytorch.html)\n",
        "\n",
        "* [how-to-use-with-numpy](https://flower.ai/docs/datasets/how-to-use-with-numpy.html)\n",
        "\n",
        "* [how-to-use-with-tensorflow](https://flower.ai/docs/datasets/how-to-use-with-tensorflow.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de14f09f0ee4f6ac",
      "metadata": {
        "id": "de14f09f0ee4f6ac"
      },
      "source": [
        "### PyTorch\n",
        "\n",
        "Transform the `Dataset` into the `DataLoader`, use the `PyTorch transforms` (`Compose` and all the others are possible)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94321ee",
      "metadata": {
        "id": "a94321ee"
      },
      "outputs": [],
      "source": [
        "! pip install -q torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "544c0e73054f3445",
      "metadata": {
        "id": "544c0e73054f3445"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "transforms = ToTensor()\n",
        "\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    # For CIFAR-10 the \"img\" column contains the images we want to apply the transforms to\n",
        "    batch[\"img\"] = [transforms(img) for img in batch[\"img\"]]\n",
        "    return batch\n",
        "\n",
        "\n",
        "partition_torch = partition.with_transform(apply_transforms)\n",
        "dataloader = DataLoader(partition_torch, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93678a5",
      "metadata": {
        "id": "b93678a5"
      },
      "source": [
        "The `Dataloader` created this way does not return a `Tuple` when iterating over it but a `Dict` with the names of the columns as keys and features as values. Look below for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5edd3ce2",
      "metadata": {
        "id": "5edd3ce2",
        "outputId": "928c543f-f259-4c8f-8907-3c7d53e29e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Return type when iterating over dataloader: <class 'dict'>\n",
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for batch in dataloader:\n",
        "    print(f\"Return type when iterating over a dataloader: {type(batch)}\")\n",
        "    print(batch[\"img\"].shape)\n",
        "    print(batch[\"label\"].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71531613",
      "metadata": {
        "id": "71531613"
      },
      "source": [
        "### NumPy\n",
        "\n",
        "NumPy can be used as input to the TensorFlow and scikit-learn models. The transformation is very simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b98b3e1",
      "metadata": {
        "id": "6b98b3e1"
      },
      "outputs": [],
      "source": [
        "partition_np = partition.with_format(\"numpy\")\n",
        "X_train, y_train = partition_np[\"img\"], partition_np[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4867834",
      "metadata": {
        "id": "e4867834"
      },
      "source": [
        "### TensorFlow Dataset\n",
        "\n",
        "Transformation to TensorFlow Dataset is a one-liner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69ce677",
      "metadata": {
        "id": "a69ce677"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db86f1aa",
      "metadata": {
        "id": "db86f1aa"
      },
      "outputs": [],
      "source": [
        "tf_dataset = partition.to_tf_dataset(\n",
        "    columns=\"img\", label_cols=\"label\", batch_size=64, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fd797c",
      "metadata": {
        "id": "61fd797c"
      },
      "source": [
        "## Final remarks\n",
        "\n",
        "Congratulations, you now know the basics of Flower Datasets and are ready to perform basic dataset preparation for Federated Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdfe1b5",
      "metadata": {
        "id": "cbdfe1b5"
      },
      "source": [
        "## Next\n",
        "\n",
        "This is the first quickstart tutorial from the Flower Datasets series. See other tutorials:\n",
        "\n",
        "* [Use Partitioners](https://flower.ai/docs/datasets/tutorial-use-partitioners.html)\n",
        "\n",
        "* [Visualize Label Distribution](https://flower.ai/docs/datasets/tutorial-visualize-label-distribution.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "flwr",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}